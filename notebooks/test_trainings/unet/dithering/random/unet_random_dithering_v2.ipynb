{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18471a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control variable: Set to True to skip training and only load/visualize existing results\n",
    "# Useful for viewing history, plotting curves, or running inference without training\n",
    "SKIP_TRAINING = False  # Set to True to skip the training loop\n",
    "\n",
    "# Telegram notifications configuration\n",
    "telegram_config = {\n",
    "    \"notify_every\": 1,  # Send notification every N epochs (0 to disable)\n",
    "    \"model_name\": \"UNet\",\n",
    "    \"degradation_info\": {\n",
    "        \"type\": \"Quantization with Dithering\",\n",
    "        \"description\": \"2-bit quantization with random dithering\",\n",
    "        \"settings\": {\n",
    "            \"Bits per channel\": 2,\n",
    "            \"Dithering type\": \"Random\",\n",
    "            \"Color levels\": \"4 (2-bit)\",\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1105f3c",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7031db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from src.degradations.generate_degraded_dataset import generate_degraded_dataset\n",
    "from src.losses.combined_loss import CombinedLoss\n",
    "from src.models.unet import UNet\n",
    "from src.training import get_dataloaders, run_training\n",
    "from src.utils import (\n",
    "    get_degraded_data_dir,\n",
    "    get_raw_data_dir,\n",
    "    load_checkpoint,\n",
    "    plot_image_comparison,\n",
    "    plot_inference_results,\n",
    "    plot_training_curves,\n",
    "    print_training_summary,\n",
    "    setup_or_resume_experiment,\n",
    "    resume_training,\n",
    "    download_div2k_dataset,\n",
    ")\n",
    "from src.evaluation import ImageRestorationEvaluator\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(\n",
    "        f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c1176",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "config = {\n",
    "    # Resume Training\n",
    "    \"resume_from_checkpoint\": False,\n",
    "    \"resume_experiment\": \"latest\",\n",
    "    # Data\n",
    "    \"train_degraded_dir\": str(\n",
    "        get_degraded_data_dir() / \"dithering\" / \"random\" / \"DIV2K_train_HR\"\n",
    "    ),\n",
    "    \"train_clean_dir\": str(get_raw_data_dir() / \"DIV2K_train_HR\"),\n",
    "    \"val_degraded_dir\": str(\n",
    "        get_degraded_data_dir() / \"dithering\" / \"random\" / \"DIV2K_valid_HR\"\n",
    "    ),\n",
    "    \"val_clean_dir\": str(get_raw_data_dir() / \"DIV2K_valid_HR\"),\n",
    "    # Training\n",
    "    \"batch_size\": 16,\n",
    "    \"num_epochs\": 35,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"weight_decay\": 1e-5,\n",
    "    # Data\n",
    "    \"patch_size\": 128,\n",
    "    \"patches_per_image\": 20,\n",
    "    \"num_workers\": 4,\n",
    "    # Model\n",
    "    \"model_features\": 64,\n",
    "    \"model_bilinear\": False,\n",
    "    # Loss\n",
    "    \"loss_alpha\": 0.84,  # L1 weight\n",
    "    \"loss_beta\": 0.16,  # SSIM weight\n",
    "    # Degradation\n",
    "    \"bits_per_channel\": 2,  # Quantization bits\n",
    "    \"dithering_type\": \"random\",  # Dithering type\n",
    "    # Optimization\n",
    "    \"scheduler\": \"cosine\",\n",
    "    \"warmup_epochs\": 5,\n",
    "    \"min_lr\": 1e-6,\n",
    "    # Early stopping\n",
    "    \"patience\": 5,\n",
    "    # Checkpoints\n",
    "    \"save_every\": 5,\n",
    "    \"val_every\": 2,\n",
    "    # Mixed Precision\n",
    "    \"use_amp\": True,\n",
    "    # Device\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "np.random.seed(config[\"seed\"])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(config[\"seed\"])\n",
    "    torch.backends.cudnn.deterministic = False\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"\\nüìã Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"   {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b948191f",
   "metadata": {},
   "source": [
    "## 3. Create Output Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef366c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup experiment directories (new or resume existing)\n",
    "exp_dir, checkpoints_dir, samples_dir, logs_dir = setup_or_resume_experiment(\n",
    "    model_name=\"unet\",\n",
    "    degradation=\"dithering/random\",\n",
    "    config=config,\n",
    "    resume_from_checkpoint=config[\"resume_from_checkpoint\"],\n",
    "    resume_experiment=config[\"resume_experiment\"],\n",
    "    custom_name=\"v2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da785ee8",
   "metadata": {},
   "source": [
    "## 4. Setup TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504ef61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorBoard writer\n",
    "writer = SummaryWriter(log_dir=logs_dir)\n",
    "\n",
    "print(f\"\\nüìä TensorBoard logs: {logs_dir}\")\n",
    "print(f\"   Run: tensorboard --logdir {logs_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b15f088",
   "metadata": {},
   "source": [
    "## 5. Generate Degraded Datasets\n",
    "\n",
    "Generate corrupted versions of DIV2K images using 2-bit random dithering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02664006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if raw datasets exist, if not download them\n",
    "train_clean_exists = Path(config[\"train_clean_dir\"]).exists()\n",
    "val_clean_exists = Path(config[\"val_clean_dir\"]).exists()\n",
    "\n",
    "if not train_clean_exists or not val_clean_exists:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üì• DIV2K Dataset Not Found - Downloading...\")\n",
    "    print(\"=\" * 80)\n",
    "    download_div2k_dataset()\n",
    "else:\n",
    "    print(\"‚úÖ DIV2K raw dataset already exists\")\n",
    "\n",
    "# Check if degraded datasets already exist\n",
    "train_degraded_exists = Path(config[\"train_degraded_dir\"]).exists()\n",
    "val_degraded_exists = Path(config[\"val_degraded_dir\"]).exists()\n",
    "\n",
    "if train_degraded_exists and val_degraded_exists:\n",
    "    n_train = len(list(Path(config[\"train_degraded_dir\"]).glob(\"*.png\")))\n",
    "    n_val = len(list(Path(config[\"val_degraded_dir\"]).glob(\"*.png\")))\n",
    "    print(\"‚úÖ Degraded datasets already exist:\")\n",
    "    print(f\"   Train: {n_train} images in {config['train_degraded_dir']}\")\n",
    "    print(f\"   Val: {n_val} images in {config['val_degraded_dir']}\")\n",
    "    print(\"\\n‚è≠Ô∏è  Skipping generation (delete folders to regenerate)\")\n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üé® Generating Degraded Datasets\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nDegradation: 2-bit random dithering\")\n",
    "    print(\"This will create corrupted versions of DIV2K images\\n\")\n",
    "\n",
    "    # Generate training dataset\n",
    "    if not train_degraded_exists:\n",
    "        print(\"üìÇ Training Dataset\")\n",
    "        generate_degraded_dataset(\n",
    "            input_dir=config[\"train_clean_dir\"],\n",
    "            output_dir=config[\"train_degraded_dir\"],\n",
    "            degradation_type=\"quantization\",\n",
    "            bits_per_channel=2,\n",
    "            dithering_type=\"random\",\n",
    "            seed=config[\"seed\"],\n",
    "        )\n",
    "\n",
    "    # Generate validation dataset\n",
    "    if not val_degraded_exists:\n",
    "        print(\"üìÇ Validation Dataset\")\n",
    "        generate_degraded_dataset(\n",
    "            input_dir=config[\"val_clean_dir\"],\n",
    "            output_dir=config[\"val_degraded_dir\"],\n",
    "            degradation_type=\"quantization\",\n",
    "            bits_per_channel=2,\n",
    "            dithering_type=\"random\",\n",
    "            seed=config[\"seed\"],\n",
    "        )\n",
    "\n",
    "    print(\"=\" * 80)\n",
    "    print(\"‚úÖ Degraded datasets generated successfully!\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227d75f1",
   "metadata": {},
   "source": [
    "## 6. Create Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab30b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_loader, val_loader = get_dataloaders(\n",
    "    train_degraded_dir=config[\"train_degraded_dir\"],\n",
    "    train_clean_dir=config[\"train_clean_dir\"],\n",
    "    val_degraded_dir=config[\"val_degraded_dir\"],\n",
    "    val_clean_dir=config[\"val_clean_dir\"],\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    patch_size=config[\"patch_size\"],\n",
    "    patches_per_image=config[\"patches_per_image\"],\n",
    "    num_workers=config[\"num_workers\"],\n",
    ")\n",
    "\n",
    "print(f\"\\n   Batches per epoch: {len(train_loader)} train, {len(val_loader)} val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fbf416",
   "metadata": {},
   "source": [
    "## 7. Visualize Sample Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a batch\n",
    "degraded_batch, clean_batch = next(iter(train_loader))\n",
    "\n",
    "print(\"Batch shapes:\")\n",
    "print(f\"   Degraded: {degraded_batch.shape}\")\n",
    "print(f\"   Clean: {clean_batch.shape}\")\n",
    "print(f\"   Range: [{degraded_batch.min():.3f}, {degraded_batch.max():.3f}]\")\n",
    "\n",
    "# Show sample using utility function\n",
    "plot_image_comparison(\n",
    "    degraded_batch=degraded_batch,\n",
    "    clean_batch=clean_batch,\n",
    "    n_samples=4,\n",
    "    save_path=samples_dir / \"training_samples.png\",\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Sample batch saved to {samples_dir / 'training_samples.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6025f569",
   "metadata": {},
   "source": [
    "## 8. Initialize Model, Loss, Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375646ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = UNet(\n",
    "    in_channels=3,\n",
    "    out_channels=3,\n",
    "    features=config[\"model_features\"],\n",
    "    bilinear=config[\"model_bilinear\"],\n",
    ").to(config[\"device\"])\n",
    "\n",
    "print(\"\\nü§ñ Model: UNet\")\n",
    "print(f\"   Parameters: {model.get_num_params():,}\")\n",
    "print(f\"   Device: {config['device']}\")\n",
    "\n",
    "# Loss function\n",
    "criterion = CombinedLoss(alpha=config[\"loss_alpha\"], beta=config[\"loss_beta\"]).to(\n",
    "    config[\"device\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nüìâ Loss: L1 + SSIM (Œ±={config['loss_alpha']}, Œ≤={config['loss_beta']})\")\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), lr=config[\"learning_rate\"], weight_decay=config[\"weight_decay\"]\n",
    ")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è  Optimizer: AdamW\")\n",
    "print(f\"   Learning rate: {config['learning_rate']}\")\n",
    "print(f\"   Weight decay: {config['weight_decay']}\")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = None\n",
    "if config[\"scheduler\"] == \"cosine\":\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer,\n",
    "        T_max=config[\"num_epochs\"] - config[\"warmup_epochs\"],\n",
    "        eta_min=config[\"min_lr\"],\n",
    "    )\n",
    "    print(\"\\nüìÖ Scheduler: CosineAnnealingLR\")\n",
    "    print(f\"   Warmup epochs: {config['warmup_epochs']}\")\n",
    "    print(f\"   Min LR: {config['min_lr']}\")\n",
    "else:\n",
    "    print(\"\\nüìÖ No scheduler configured\")\n",
    "\n",
    "# Resume from checkpoint if enabled\n",
    "start_epoch = 0\n",
    "initial_best_loss = float(\"inf\")\n",
    "initial_best_epoch = 0\n",
    "initial_history = None\n",
    "\n",
    "if config[\"resume_from_checkpoint\"]:\n",
    "    (\n",
    "        checkpoint_info,\n",
    "        start_epoch,\n",
    "        initial_history,\n",
    "        resume_exp_dir,\n",
    "        initial_best_epoch,\n",
    "    ) = resume_training(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        experiment_path=config[\"resume_experiment\"],\n",
    "        model_name=\"unet\",\n",
    "        degradation=\"dithering/random\",\n",
    "        device=config[\"device\"],\n",
    "    )\n",
    "    initial_best_loss = (\n",
    "        checkpoint_info[\"metrics\"].get(\"val\", {}).get(\"loss\", float(\"inf\"))\n",
    "    )\n",
    "\n",
    "    # Verify that resume_exp_dir matches our exp_dir\n",
    "    if resume_exp_dir != exp_dir:\n",
    "        print(\"‚ö†Ô∏è  Warning: Resume experiment mismatch!\")\n",
    "        print(f\"   Expected: {exp_dir}\")\n",
    "        print(f\"   Got: {resume_exp_dir}\")\n",
    "        print(f\"   Using: {exp_dir}\")\n",
    "else:\n",
    "    print(\"\\nüÜï Starting fresh training (resume_from_checkpoint=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3486c2e4",
   "metadata": {},
   "source": [
    "## 9. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1818df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not SKIP_TRAINING:\n",
    "    # Run training\n",
    "    history, best_info = run_training(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        device=config[\"device\"],\n",
    "        num_epochs=config[\"num_epochs\"],\n",
    "        checkpoints_dir=checkpoints_dir,\n",
    "        writer=writer,\n",
    "        warmup_epochs=config[\"warmup_epochs\"],\n",
    "        learning_rate=config[\"learning_rate\"],\n",
    "        patience=config[\"patience\"],\n",
    "        save_every=config[\"save_every\"],\n",
    "        val_every=config[\"val_every\"],\n",
    "        start_epoch=start_epoch,\n",
    "        initial_best_loss=initial_best_loss,\n",
    "        initial_best_epoch=initial_best_epoch,  # Pass best epoch from checkpoint\n",
    "        initial_history=initial_history,  # Continue from previous history\n",
    "        use_amp=config[\"use_amp\"],  # Enable/disable mixed precision training\n",
    "        config=config,  # Training configuration\n",
    "        telegram_config=telegram_config,  # Telegram notifications config\n",
    "    )\n",
    "\n",
    "    # Extract best model info\n",
    "    best_epoch = best_info[\"best_epoch\"]\n",
    "    best_val_loss = best_info[\"best_val_loss\"]\n",
    "\n",
    "    print(f\"‚úÖ Training history saved to {exp_dir / 'history.json'}\")\n",
    "else:\n",
    "    # Skip training: Load existing history and best model info\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚è≠Ô∏è  SKIP_TRAINING = True: Loading existing results\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    from src.utils.experiment import load_training_history\n",
    "\n",
    "    try:\n",
    "        history = load_training_history(exp_dir)\n",
    "        print(f\"‚úÖ Loaded history from {exp_dir / 'history.json'}\")\n",
    "        print(f\"   Total epochs: {len(history['train_loss'])}\")\n",
    "\n",
    "        # Find best epoch from history\n",
    "        if history.get(\"val_loss\"):\n",
    "            best_val_loss = min(history[\"val_loss\"])\n",
    "            best_epoch = history[\"val_loss\"].index(best_val_loss) + 1\n",
    "            print(f\"   Best epoch: {best_epoch} (val_loss: {best_val_loss:.4f})\")\n",
    "        else:\n",
    "            best_val_loss = float(\"inf\")\n",
    "            best_epoch = 0\n",
    "            print(\"   No validation history found\")\n",
    "\n",
    "        # Create best_info dict for consistency\n",
    "        best_info = {\"best_epoch\": best_epoch, \"best_val_loss\": best_val_loss}\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ö†Ô∏è  No history found in {exp_dir}\")\n",
    "        print(\"   Creating empty history (train first to generate data)\")\n",
    "        history = {\n",
    "            \"train_loss\": [],\n",
    "            \"train_l1\": [],\n",
    "            \"train_ssim\": [],\n",
    "            \"val_loss\": [],\n",
    "            \"val_l1\": [],\n",
    "            \"val_ssim\": [],\n",
    "            \"lr\": [],\n",
    "        }\n",
    "        best_epoch = 0\n",
    "        best_val_loss = float(\"inf\")\n",
    "        best_info = {\"best_epoch\": best_epoch, \"best_val_loss\": best_val_loss}\n",
    "\n",
    "    print(\"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dd2119",
   "metadata": {},
   "source": [
    "## 10. Plot Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d2fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves using utility function\n",
    "plot_training_curves(history=history, save_path=exp_dir / \"training_curves.png\")\n",
    "\n",
    "print(f\"\\n‚úÖ Training curves saved to {exp_dir / 'training_curves.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d2ae88",
   "metadata": {},
   "source": [
    "## 11. Test Inference on Validation Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8dbc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint_info = load_checkpoint(\n",
    "    checkpoints_dir / \"best_model.pth\", model=model, device=config[\"device\"]\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Loaded best model from epoch {checkpoint_info['epoch']}\")\n",
    "\n",
    "# Get validation batch\n",
    "degraded_batch, clean_batch = next(iter(val_loader))\n",
    "degraded_batch = degraded_batch.to(config[\"device\"])\n",
    "clean_batch = clean_batch.to(config[\"device\"])\n",
    "\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    restored_batch = model(degraded_batch)\n",
    "\n",
    "# Visualize results using utility function\n",
    "plot_inference_results(\n",
    "    degraded_batch=degraded_batch,\n",
    "    restored_batch=restored_batch,\n",
    "    clean_batch=clean_batch,\n",
    "    n_samples=4,\n",
    "    save_path=samples_dir / \"inference_results.png\",\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Inference results saved to {samples_dir / 'inference_results.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5827531",
   "metadata": {},
   "source": [
    "## 12. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print training summary\n",
    "print_training_summary(\n",
    "    history=history,\n",
    "    best_epoch=best_epoch,\n",
    "    best_val_loss=best_val_loss,\n",
    "    exp_dir=exp_dir,\n",
    "    checkpoints_dir=checkpoints_dir,\n",
    "    samples_dir=samples_dir,\n",
    "    logs_dir=logs_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdde6b7",
   "metadata": {},
   "source": [
    "## 13. Quantitative Evaluation on Full-Resolution Images\n",
    "\n",
    "Evaluate the model on entire validation images using sliding window inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2ba145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluator\n",
    "evaluator = ImageRestorationEvaluator(\n",
    "    model=model,\n",
    "    device=config[\"device\"],\n",
    "    patch_size=config[\"patch_size\"],\n",
    "    overlap=32,  # Overlap for smooth blending\n",
    ")\n",
    "\n",
    "print(\"\\nüîç Evaluator configured:\")\n",
    "print(f\"   Patch size: {config['patch_size']}\")\n",
    "print(\"   Overlap: 32 pixels\")\n",
    "print(f\"   Device: {config['device']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6e163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set (limit to 10 images for speed)\n",
    "eval_results = evaluator.evaluate_dataset(\n",
    "    degraded_dir=config[\"val_degraded_dir\"],\n",
    "    clean_dir=config[\"val_clean_dir\"],\n",
    "    output_dir=exp_dir / \"restored_images\",\n",
    "    save_outputs=True,  # Save restored images\n",
    "    max_images=10,  # Change to None to evaluate all images\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "evaluator.print_summary(eval_results)\n",
    "\n",
    "# Save results\n",
    "evaluator.save_results(eval_results, exp_dir / \"evaluation_metrics.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11fb23f",
   "metadata": {},
   "source": [
    "## 14. Visualize Full-Resolution Restoration\n",
    "\n",
    "Show best and worst restoration results on full images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a5b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best and worst images\n",
    "best_img = max(eval_results[\"per_image\"], key=lambda x: x[\"psnr\"])\n",
    "worst_img = min(eval_results[\"per_image\"], key=lambda x: x[\"psnr\"])\n",
    "\n",
    "\n",
    "# Load images for visualization\n",
    "def load_image_trio(filename):\n",
    "    degraded_path = Path(config[\"val_degraded_dir\"]) / filename\n",
    "    clean_path = Path(config[\"val_clean_dir\"]) / filename\n",
    "    restored_path = exp_dir / \"restored_images\" / filename\n",
    "\n",
    "    degraded = cv2.cvtColor(cv2.imread(str(degraded_path)), cv2.COLOR_BGR2RGB)\n",
    "    clean = cv2.cvtColor(cv2.imread(str(clean_path)), cv2.COLOR_BGR2RGB)\n",
    "    restored = cv2.cvtColor(cv2.imread(str(restored_path)), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return degraded, restored, clean\n",
    "\n",
    "\n",
    "# Visualize best result\n",
    "print(f\"\\nüèÜ Best result: {best_img['filename']}\")\n",
    "print(f\"   PSNR: {best_img['psnr']:.2f} dB, SSIM: {best_img['ssim']:.4f}\")\n",
    "\n",
    "deg, res, cln = load_image_trio(best_img[\"filename\"])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(deg)\n",
    "axes[0].set_title(\"Degraded\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(res)\n",
    "axes[1].set_title(f\"Restored\\nPSNR: {best_img['psnr']:.2f} dB\")\n",
    "axes[1].axis(\"off\")\n",
    "axes[2].imshow(cln)\n",
    "axes[2].set_title(\"Ground Truth\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Best Result: {best_img['filename']}\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(samples_dir / \"best_full_restoration.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize worst result\n",
    "print(f\"\\n‚ö†Ô∏è Worst result: {worst_img['filename']}\")\n",
    "print(f\"   PSNR: {worst_img['psnr']:.2f} dB, SSIM: {worst_img['ssim']:.4f}\")\n",
    "\n",
    "deg, res, cln = load_image_trio(worst_img[\"filename\"])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(deg)\n",
    "axes[0].set_title(\"Degraded\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(res)\n",
    "axes[1].set_title(f\"Restored\\nPSNR: {worst_img['psnr']:.2f} dB\")\n",
    "axes[1].axis(\"off\")\n",
    "axes[2].imshow(cln)\n",
    "axes[2].set_title(\"Ground Truth\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "plt.suptitle(f\"Worst Result: {worst_img['filename']}\", fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(samples_dir / \"worst_full_restoration.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Image-Enhancement (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
